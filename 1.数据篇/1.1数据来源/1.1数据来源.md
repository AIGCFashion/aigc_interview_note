1.1 数据来源
预训练数据可以分为通用文本数据和专用文本数据，其中通用文本数据规模较大，涵盖了网页、书籍和对话等内容，用以增强模型的语言建模能力；专用文本数据则是为了进一步提升大语言模型在特定任务上的表现，如多语数据、科学数据和代码数据等。
![alt text](image.png)
图 1.1 LLM 数据源分布
